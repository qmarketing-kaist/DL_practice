{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "tf.set_random_seed(777)  # for reproducibility\n",
    "\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)\n",
    "\n",
    "# parameters\n",
    "nb_classes = 10\n",
    "num_epochs = 15\n",
    "batch_size = 100\n",
    "num_iterations = int(mnist.train.num_examples / batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "# input place holders\n",
    "X = tf.placeholder(tf.float32, [None, 784])\n",
    "Y = tf.placeholder(tf.float32, [None, 10])\n",
    "\n",
    "# weights & bias for nn layers\n",
    "W1 = tf.get_variable(\"W1\", shape=[784, 392],\n",
    "                     initializer=tf.contrib.layers.xavier_initializer())\n",
    "b1 = tf.Variable(tf.random_normal([392]))\n",
    "L1 = tf.nn.relu(tf.matmul(X, W1) + b1)\n",
    "\n",
    "W2 = tf.get_variable(\"W2\", shape=[392, 392],\n",
    "                     initializer=tf.contrib.layers.xavier_initializer())\n",
    "b2 = tf.Variable(tf.random_normal([392]))\n",
    "L2 = tf.nn.relu(tf.matmul(L1, W2) + b2)\n",
    "\n",
    "W3 = tf.get_variable(\"W3\", shape=[392, 10],\n",
    "                     initializer=tf.contrib.layers.xavier_initializer())\n",
    "b3 = tf.Variable(tf.random_normal([10]))\n",
    "hypothesis = tf.matmul(L2, W3) + b3\n",
    "\n",
    "# define cost/loss & optimizer\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(\n",
    "    logits=hypothesis, labels=Y))\n",
    "train = tf.train.AdamOptimizer(learning_rate=0.001).minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0001 cost = 0.279559917\n",
      "Epoch: 0002 cost = 0.102466174\n",
      "Epoch: 0003 cost = 0.064555062\n",
      "Epoch: 0004 cost = 0.044983712\n",
      "Epoch: 0005 cost = 0.031848409\n",
      "Epoch: 0006 cost = 0.027033243\n",
      "Epoch: 0007 cost = 0.021393424\n",
      "Epoch: 0008 cost = 0.015989656\n",
      "Epoch: 0009 cost = 0.016949181\n",
      "Epoch: 0010 cost = 0.013322478\n",
      "Epoch: 0011 cost = 0.011728490\n",
      "Epoch: 0012 cost = 0.011204075\n",
      "Epoch: 0013 cost = 0.009883816\n",
      "Epoch: 0014 cost = 0.011102427\n",
      "Epoch: 0015 cost = 0.008209764\n",
      "Learning Finished\n"
     ]
    }
   ],
   "source": [
    "# initialize\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "# Training\n",
    "for epoch in range(num_epochs):\n",
    "    avg_cost = 0\n",
    "    for i in range(num_iterations):\n",
    "        batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
    "        _, cost_val = sess.run([train, cost], feed_dict={X: batch_xs, Y: batch_ys})\n",
    "        avg_cost += cost_val / num_iterations\n",
    "        \n",
    "    print('Epoch:', '%04d' % (epoch + 1), 'cost =', '{:.9f}'.format(avg_cost))\n",
    "\n",
    "print('Learning Finished')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9771\n",
      "Label:  [7]\n",
      "Prediction:  [7]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Testing and Accuracy\n",
    "is_correct = tf.equal(tf.argmax(hypothesis, 1), tf.argmax(Y, 1)) # test model prediction\n",
    "accuracy = tf.reduce_mean(tf.cast(is_correct, tf.float32)) # calculate accuracy\n",
    "print('Accuracy:', sess.run(accuracy, feed_dict={X:mnist.test.images, Y:mnist.test.labels}))\n",
    "\n",
    "# Get one and predict\n",
    "r = random.randint(0, mnist.test.num_examples - 1)\n",
    "print(\"Label: \", sess.run(tf.argmax(mnist.test.labels[r : r + 1], 1)))\n",
    "print(\n",
    "    \"Prediction: \",\n",
    "    sess.run(tf.argmax(hypothesis, 1), feed_dict={X: mnist.test.images[r : r + 1]}),\n",
    ")\n",
    "\n",
    "plt.imshow(\n",
    "    mnist.test.images[r : r + 1].reshape(28, 28),\n",
    "    cmap=\"Greys\",\n",
    "    interpolation=\"nearest\",\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
